---
title: Insert title here
key: 5b71d68181d2c17f7b150f2e56187580

---
## Introduction to Convolutional Neural Networks

```yaml
type: "TitleSlide"
key: "4d53f6c1e6"
```

`@lower_third`

name: Farshad Nasiri, PhD
title: Data Scientist


`@script`
Welcome back! By now you are able to create fully-connected feed forward NNs. In this chapter we will see how NNs can be used for processing images and why a special kind of network is needed for this purpose.


---
## Example: Image classification!

```yaml
type: "FullSlide"
key: "7b1a21f347"
center_content: true
```

`@part1`
Is there a car in the picture?{{1}}

![](http://assets.datacamp.com/production/repositories/4036/datasets/4a9637f9cc49c0a9b590b487354a614196e9bedd/bothPics.jpg){{2}}


`@script`
Consider this example: You have been asked to train a NN that is able to detect if there is a car in a given picture. This is useful in automated driving applications.

The picture to the left does contain a car. The one to the right doesn't. This is a binary classification problem.


---
## Using dense feed forward NNs for image classification

```yaml
type: "FullSlide"
key: "149b6e1744"
center_content: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/4036/datasets/075ac14bdab3b3169a016460cdd06226ddb79933/dataset.jpg){{1}}

Each picture has to be passed to the NN for training.{{2}}


`@script`
Suppose you have a dataset of pictures with or without cars in them and the dataset is labeled. Let's see what happens if we use a dense feed forward NN.
Each picture in the dataset, along with its label has to be passed to the NN for training.


---
## Using dense feed forward NNs for image classification

```yaml
type: "FullSlide"
key: "2db3c67612"
center_content: true
```

`@part1`
- Assume each picture is 200 by 100 pixels and is greyscale.{{1}}
- This means that our input layer has 200x100=20,000 nodes.{{2}}
- Let's say that our first hidden layer has 100 nodes.{{3}}

![](http://assets.datacamp.com/production/repositories/4036/datasets/4c32cb3fa77d5b1728be010ae4b6cbf7ac854f7c/layers_small.png){{4}}


`@script`
Assume each picture is 200 by 100 pixels and is greyscale. In greyscale images, each pixel has an integer value between 0 and 255. Zero for black and 255 for white. The numbers in between, represent different shades of grey.
This means out input layer has 200x100=20,000 nodes.
Let's say that our first hidden layer has 100 nodes.
As you can see in the diagram, each pixel, is passed on to each of the nodes and each node has an associated bias term.


---
## Using dense feed forward NNs for image classification

```yaml
type: "FullSlide"
key: "2ac0083e25"
center_content: true
```

`@part1`
- We need to learn 20,000x100+100=2,000,100 parameters.
- Dense NNs are impractical for object detection.
- Convolutional NNs solve this problem.


`@script`
A simple calculation reveals that we need to learn around 2 million parameters only for the first layer!

Given that a NN typically has multiple layers, it is easy to see how computationally expensive dense networks are for object detection.

This is a problem and makes dense NNs impractical for this application. The way to get around it is to use CNNs. In the next exercise, we will learn about these networks.


---
## Convolutional Neural Networks

```yaml
type: "FullSlide"
key: "f9223d769e"
```

`@part1`
![](http://assets.datacamp.com/production/repositories/4036/datasets/7c0b7c064a6ebcec817642f2a2935bd7505272f2/CNN_demo.png)


`@script`
Here is a conceptual demonstration of CNNs. This network in particular identifies the model of a vehicle in a picture. A CNN is made up of several convolutional layers. At the early layers, the network learns abstract and general features of a picture such as edges. As the information is passed down to the deeper layers, the network learns more detailed features of the vehicle such as wheels and headlights. Finally, the output of the convolutional layers is passed to an ordinary NN for classification. Let's how this looks in code form.


---
## Convolutional Neural Networks

```yaml
type: "FullSlide"
key: "71082a1f10"
```

`@part1`
[1] `from keras.models import Sequential`

[2] `from keras.layers import Conv2D`

[3] `model = Sequential()`

[4] `model.add(Conv2D(filters=32,kernel_size=(3,3),
activation='relu',input_shape=(10, 128)))`

[5] `model.add(Conv2D(64, (3, 3), activation='relu'))`


`@script`
Constructing a CNN in Keras is similar to creating fully connected NNs. In the first two lines we import the required libraries. In line 3, we instantiate our model. Line 4 adds the first convolution layer. Filters, defines the number of convolutions in this layer and kernel_size defines the size of the convolution filter. We will talk about these concepts in later slides. Finally we define the type of activation function and specify the size of the inputs just like we did in fully connected NNs.


---
## What is convolution?

```yaml
type: "FullSlide"
key: "2494f40727"
```

`@part1`
![](http://assets.datacamp.com/production/repositories/4036/datasets/ce7aa238925327ab03346f619eabd7e5586ae0bb/c1)


`@script`
We have a 6 by 6 image and a 3 by 3 filter, also known as a kernel.


---
## What is convolution?

```yaml
type: "FullSlide"
key: "b8aa252235"
```

`@part1`
![](http://assets.datacamp.com/production/repositories/4036/datasets/9cc36c8e9624f50172b4a23d69bc2a9e0369e709/c2.png)

C = 3x1+0x0+1x(-1)+1x1+5x0+8x(-1)+2x1+7x0+2x(-1)=-5


`@script`
To perform convolution, we place the kernel on top of the image and multiply the values element-wise and sum them up


---
## What is convolution?

```yaml
type: "FullSlide"
key: "1c46bb8ef7"
```

`@part1`
![](http://assets.datacamp.com/production/repositories/4036/datasets/4d59bc7dab901130719d90f83aaf431bf735b4c5/c3)


`@script`
We will then shift the kernel and perform the same calculation.


---
## What is convolution?

```yaml
type: "FullSlide"
key: "bc50f9f8ec"
```

`@part1`
![](image-url)


`@script`
We will continue doing so until the entire image is covered.


---
## Final Slide

```yaml
type: "FinalSlide"
key: "c6ac0fe876"
```

`@script`


